{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial T02a: Gradients of Covariance Decomposition (gradcovcor).\n",
    "\n",
    "The covariance matrix Omega is parameterized as:\n    Omega = diag(omega) @ Omega_star @ diag(omega)\nwhere omega are standard deviations and Omega_star is the correlation matrix.\n\ngradcovcor computes the Jacobians in BHATLIB's row-based arrangement:\n  - glitomega: shape (K, n_cov) — d(vecdup Omega) / d(omega)\n  - gomegastar: shape (n_corr, n_cov) — d(vecdup Omega) / d(off-diag Omega*)\n\nWhat you will learn:\n  - Building Omega from omega and Omega_star\n  - Computing and interpreting gradcovcor output\n  - Verifying gradients via finite differences\n  - Why this decomposition matters for unconstrained optimization\n\nPrerequisites: t01a (vectorization).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, sys\nimport numpy as np\nnp.set_printoptions(precision=4, suppress=True)\nimport pathlib\nsys.path.insert(0, str(pathlib.Path.cwd().parent.parent / \"src\"))\n\nfrom pybhatlib.matgradient import gradcovcor, GradCovCorResult\nfrom pybhatlib.vecup import vecdup, vecndup, matdupfull\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Build Covariance from Std Devs and Correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "K = 3\nomega = np.array([2.0, 1.5, 1.0])   # standard deviations\nOmega_star = np.array([              # correlation matrix\n    [1.0, 0.6, 0.3],\n    [0.6, 1.0, 0.5],\n    [0.3, 0.5, 1.0],\n])\n\n# Omega = diag(omega) @ Omega_star @ diag(omega)\nOmega = np.diag(omega) @ Omega_star @ np.diag(omega)\n\nprint(f\"\\n  omega (std devs) = {omega}\")\nprint(f\"  Omega_star (correlations) =\\n{Omega_star}\")\nprint(f\"  Omega (covariance) =\\n{Omega}\")\nprint(f\"\\n  Note: Omega[0,0] = omega[0]^2 = {omega[0]**2:.1f}\")\nprint(f\"  Omega[0,1] = omega[0]*rho_01*omega[1] = {omega[0]*0.6*omega[1]:.1f}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compute gradcovcor Jacobians\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result = gradcovcor(Omega)\n\nn_cov = K * (K + 1) // 2   # = 6 upper-tri elements of Omega\nn_corr = K * (K - 1) // 2  # = 3 off-diagonal correlation elements\n\nprint(f\"\\n  glitomega shape: {result.glitomega.shape}\")\nprint(f\"    Rows = K = {K} (one per std dev omega_k)\")\nprint(f\"    Cols = K*(K+1)/2 = {n_cov} (vecdup of Omega)\")\nprint(f\"    glitomega[k, c] = d(Omega_c) / d(omega_k)\")\n\nprint(f\"\\n  gomegastar shape: {result.gomegastar.shape}\")\nprint(f\"    Rows = K*(K-1)/2 = {n_corr} (off-diagonal correlations)\")\nprint(f\"    Cols = K*(K+1)/2 = {n_cov} (vecdup of Omega)\")\n\nprint(f\"\\n  glitomega =\\n{result.glitomega}\")\nprint(f\"\\n  gomegastar =\\n{result.gomegastar}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify glitomega (d vecdup(Omega) / d omega)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "eps = 1e-7\nglitomega_fd = np.zeros_like(result.glitomega)\n\nfor k in range(K):\n    omega_plus = omega.copy(); omega_plus[k] += eps\n    omega_minus = omega.copy(); omega_minus[k] -= eps\n    Omega_plus = np.diag(omega_plus) @ Omega_star @ np.diag(omega_plus)\n    Omega_minus = np.diag(omega_minus) @ Omega_star @ np.diag(omega_minus)\n    # Row k of glitomega: how each vecdup(Omega) element changes with omega_k\n    glitomega_fd[k, :] = (vecdup(Omega_plus) - vecdup(Omega_minus)) / (2 * eps)\n\nmax_err = np.max(np.abs(result.glitomega - glitomega_fd))\nprint(f\"\\n  Finite difference step: eps = {eps}\")\nprint(f\"  Max error |analytic - numerical|: {max_err:.2e}\")\nprint(f\"  Verification passed: {max_err < 1e-4}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Verify gomegastar (d vecdup(Omega) / d off-diag Omega*)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Off-diagonal elements of Omega_star (upper-triangular, no diagonal)\noffdiag_elements = vecndup(Omega_star)\ngomegastar_fd = np.zeros_like(result.gomegastar)\n\n# Enumerate off-diagonal upper-tri positions\noffdiag_idx = 0\nfor i in range(K):\n    for j in range(i + 1, K):\n        Ostar_plus = Omega_star.copy()\n        Ostar_plus[i, j] += eps; Ostar_plus[j, i] += eps\n        Omega_plus = np.diag(omega) @ Ostar_plus @ np.diag(omega)\n\n        Ostar_minus = Omega_star.copy()\n        Ostar_minus[i, j] -= eps; Ostar_minus[j, i] -= eps\n        Omega_minus = np.diag(omega) @ Ostar_minus @ np.diag(omega)\n\n        gomegastar_fd[offdiag_idx, :] = (\n            vecdup(Omega_plus) - vecdup(Omega_minus)\n        ) / (2 * eps)\n        offdiag_idx += 1\n\nmax_err2 = np.max(np.abs(result.gomegastar - gomegastar_fd))\nprint(f\"\\n  Max error |analytic - numerical|: {max_err2:.2e}\")\nprint(f\"  Verification passed: {max_err2 < 1e-4}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Why Decompose Covariance This Way?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\"\"\n  Optimization requires unconstrained parameters, but:\n  - Standard deviations omega must be positive -> log(omega) is unconstrained\n  - Correlations must satisfy |rho| < 1 and Omega* must be PD\n    -> spherical parameterization (see t02b) maps R^n to valid correlations\n\n  gradcovcor provides the chain rule pieces:\n    d(loss)/d(omega) = glitomega @ d(loss)/d(vecdup Omega)\n    d(loss)/d(Omega*) = gomegastar @ d(loss)/d(vecdup Omega)\n\n  This makes gradient-based optimization of the covariance matrix possible\n  while maintaining all required constraints.\n\"\"\")\n\nprint(f\"  Next: t02b_spherical.py — Spherical parameterization of correlations\")\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}