{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial T02b: Spherical Parameterization of Correlations.\n",
    "\n",
    "For unconstrained optimization, we need to map free parameters theta in R^n\nto a valid positive definite correlation matrix Omega*. The spherical\nparameterization achieves this via hyperspherical coordinates.\n\nWhat you will learn:\n  - theta_to_corr: convert angles to a valid PD correlation matrix\n  - grad_corr_theta: Jacobian d(vecdup Omega*)/d(theta)\n  - Verification via finite differences\n  - Why this is better than direct correlation parameterization\n\nPrerequisites: t02a (gradcovcor).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, sys\nimport numpy as np\nnp.set_printoptions(precision=4, suppress=True)\nimport pathlib\nsys.path.insert(0, str(pathlib.Path.cwd().parent.parent / \"src\"))\n\nfrom pybhatlib.matgradient import theta_to_corr, grad_corr_theta\nfrom pybhatlib.vecup import vecdup\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Angles -> Correlation Matrix (K=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "K = 3\nn_theta = K * (K - 1) // 2  # = 3 free parameters\nn_upper = K * (K + 1) // 2  # = 6 upper-tri elements\n\ntheta = np.array([0.5, 0.3, -0.2])\nR = theta_to_corr(theta, K)\n\nprint(f\"\\n  K = {K}, n_theta = {n_theta}\")\nprint(f\"  theta = {theta}\")\nprint(f\"\\n  Omega* = theta_to_corr(theta, K) =\\n{R}\")\nprint(f\"\\n  Diagonal = {np.diag(R)}  (should be all 1.0)\")\nprint(f\"  Symmetric: {np.allclose(R, R.T)}\")\nprint(f\"  Eigenvalues: {np.linalg.eigvalsh(R)}  (should be all positive)\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Always Valid for Any Theta\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rng = np.random.default_rng(42)\nprint(f\"\\n  Testing 5 random theta vectors:\")\nprint(f\"  {'theta':>30s} {'min_eig':>10s} {'diag=1':>8s} {'symm':>6s}\")\nprint(f\"  {'-'*56}\")\n\nfor _ in range(5):\n    theta_rand = rng.uniform(-3, 3, size=n_theta)\n    R_rand = theta_to_corr(theta_rand, K)\n    min_eig = np.linalg.eigvalsh(R_rand).min()\n    diag_ok = np.allclose(np.diag(R_rand), 1.0)\n    symm_ok = np.allclose(R_rand, R_rand.T)\n    theta_str = \"[\" + \", \".join(f\"{t:+.2f}\" for t in theta_rand) + \"]\"\n    print(f\"  {theta_str:>30s} {min_eig:>10.4f} {str(diag_ok):>8s} {str(symm_ok):>6s}\")\n\nprint(f\"\\n  Key property: ANY theta in R^{n_theta} maps to a valid PD correlation matrix.\")\nprint(f\"  This makes unconstrained optimization possible.\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Jacobian grad_corr_theta\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "J = grad_corr_theta(theta, K)\n\nprint(f\"\\n  Jacobian shape: {J.shape}\")\nprint(f\"    Rows = n_theta = {n_theta} (free angle parameters)\")\nprint(f\"    Cols = K*(K+1)/2 = {n_upper} (vecdup of Omega*)\")\nprint(f\"    J[p, q] = d(Omega*_q) / d(theta_p)\")\nprint(f\"\\n  J =\\n{J}\")\n\n# Verify via finite differences\neps = 1e-7\nJ_fd = np.zeros_like(J)\nfor p in range(n_theta):\n    theta_plus = theta.copy(); theta_plus[p] += eps\n    theta_minus = theta.copy(); theta_minus[p] -= eps\n    R_plus = theta_to_corr(theta_plus, K)\n    R_minus = theta_to_corr(theta_minus, K)\n    J_fd[p, :] = (vecdup(R_plus) - vecdup(R_minus)) / (2 * eps)\n\nmax_err = np.max(np.abs(J - J_fd))\nprint(f\"\\n  Finite difference verification:\")\nprint(f\"  Max error: {max_err:.2e}\")\nprint(f\"  Passed: {max_err < 1e-4}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Scalability — K=4\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "K4 = 4\nn_theta4 = K4 * (K4 - 1) // 2  # = 6\ntheta4 = rng.standard_normal(n_theta4) * 0.5\nR4 = theta_to_corr(theta4, K4)\nJ4 = grad_corr_theta(theta4, K4)\n\nprint(f\"\\n  K=4: n_theta = {n_theta4}\")\nprint(f\"  theta = {theta4}\")\nprint(f\"  Omega* =\\n{R4}\")\nprint(f\"  Eigenvalues: {np.linalg.eigvalsh(R4)}\")\nprint(f\"  Jacobian shape: {J4.shape}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Why Spherical Parameterization?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\"\"\n  Direct parameterization of correlations is problematic:\n  1. Individual correlations must satisfy |rho_ij| < 1\n  2. The correlation matrix must be positive definite\n  3. These constraints are coupled — not a simple box constraint\n\n  Spherical parameterization solves all three:\n  - Maps any vector theta in R^(K(K-1)/2) to a valid PD correlation\n  - The mapping is smooth and differentiable\n  - Gradient computation is exact via grad_corr_theta\n\n  In the MNP estimation pipeline:\n    theta (unconstrained) -> Omega* (correlation) -> Omega (covariance)\n  with gradients flowing backward through:\n    grad_corr_theta -> gomegastar -> glitomega\n\"\"\")\n\nprint(f\"  Next: t02c_chain_rules.py — Composing matrix gradients via chain rules\")\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}