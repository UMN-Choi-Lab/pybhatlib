{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial T03c: Rectangular MVNCD.\n",
    "\n",
    "Standard MVNCD computes P(X <= b). Rectangular MVNCD computes\nP(a <= X <= b), the probability that X falls within a box.\nThis is needed for ordered response models (MORP).\n\nWhat you will learn:\n  - mvncd_rect: P(lower <= X <= upper)\n  - Relation to standard MVNCD via inclusion-exclusion\n  - K=2 detailed verification with 4 terms\n  - Connection to ordered probit threshold bounds\n\nPrerequisites: t03a (MVNCD methods).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, sys\nimport numpy as np\nnp.set_printoptions(precision=4, suppress=True)\nimport pathlib\nsys.path.insert(0, str(pathlib.Path.cwd().parent.parent / \"src\"))\n\nfrom pybhatlib.gradmvn import mvncd, mvncd_rect\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Standard vs Rectangular MVNCD\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sigma = np.array([[1.0, 0.3], [0.3, 1.0]])\n\n# Standard: P(X <= b)\nb = np.array([1.0, 0.5])\np_standard = mvncd(b, sigma, method=\"scipy\")\n\n# Rectangular: P(a <= X <= b)\na = np.array([-1.0, -0.5])\np_rect = mvncd_rect(a, b, sigma, method=\"scipy\")\n\nprint(f\"\\n  sigma = {sigma.tolist()}\")\nprint(f\"\\n  Standard MVNCD:   P(X <= [{b[0]}, {b[1]}]) = {p_standard:.6f}\")\nprint(f\"  Rectangular MVNCD: P([{a[0]}, {a[1]}] <= X <= [{b[0]}, {b[1]}]) = {p_rect:.6f}\")\nprint(f\"\\n  Rectangular probability < standard (tighter region)\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: K=2 Inclusion-Exclusion Verification\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# P(a <= X <= b) = P(X <= b) - P(X1 <= a1, X2 <= b2)\n#                              - P(X1 <= b1, X2 <= a2)\n#                              + P(X1 <= a1, X2 <= a2)\n# = P(X<=b) - P(X<=[a1,b2]) - P(X<=[b1,a2]) + P(X<=a)\n\np_bb = mvncd(np.array([b[0], b[1]]), sigma, method=\"scipy\")   # P(X <= [b1, b2])\np_ab = mvncd(np.array([a[0], b[1]]), sigma, method=\"scipy\")   # P(X <= [a1, b2])\np_ba = mvncd(np.array([b[0], a[1]]), sigma, method=\"scipy\")   # P(X <= [b1, a2])\np_aa = mvncd(np.array([a[0], a[1]]), sigma, method=\"scipy\")   # P(X <= [a1, a2])\n\np_incl_excl = p_bb - p_ab - p_ba + p_aa\n\nprint(f\"\\n  Inclusion-exclusion for K=2:\")\nprint(f\"    P(X <= [b1,b2])  = {p_bb:>10.6f}  (all within upper)\")\nprint(f\"  - P(X <= [a1,b2])  = {p_ab:>10.6f}  (X1 too low)\")\nprint(f\"  - P(X <= [b1,a2])  = {p_ba:>10.6f}  (X2 too low)\")\nprint(f\"  + P(X <= [a1,a2])  = {p_aa:>10.6f}  (double subtraction)\")\nprint(f\"  = P(a <= X <= b)   = {p_incl_excl:>10.6f}\")\nprint(f\"\\n  mvncd_rect result  = {p_rect:>10.6f}\")\nprint(f\"  Match: {abs(p_rect - p_incl_excl) < 1e-4}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: K=3 with Partial Lower Bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sigma3 = np.array([\n    [1.0, 0.3, 0.1],\n    [0.3, 1.0, 0.4],\n    [0.1, 0.4, 1.0],\n])\n\nlower3 = np.array([-np.inf, -1.0, -0.5])\nupper3 = np.array([1.0, 0.5, np.inf])\n\np_rect3 = mvncd_rect(lower3, upper3, sigma3, method=\"scipy\")\n\nprint(f\"\\n  lower = [{lower3[0]}, {lower3[1]}, {lower3[2]}]\")\nprint(f\"  upper = [{upper3[0]}, {upper3[1]}, {upper3[2]}]\")\nprint(f\"\\n  P(lower <= X <= upper) = {p_rect3:.6f}\")\nprint(f\"\\n  -inf lower bound on X1 means: no lower constraint on X1\")\nprint(f\"  +inf upper bound on X3 means: no upper constraint on X3\")\n\n# When all lowers are -inf, rectangular = standard\nlower_all_inf = np.array([-np.inf, -np.inf, -np.inf])\nupper_std = np.array([1.0, 0.5, 0.0])\np_rect_std = mvncd_rect(lower_all_inf, upper_std, sigma3, method=\"scipy\")\np_std = mvncd(upper_std, sigma3, method=\"scipy\")\n\nprint(f\"\\n  Special case: all lower = -inf\")\nprint(f\"    mvncd_rect([-inf,-inf,-inf], [1,0.5,0])  = {p_rect_std:.6f}\")\nprint(f\"    mvncd([1, 0.5, 0])                       = {p_std:.6f}\")\nprint(f\"    Match: {abs(p_rect_std - p_std) < 1e-4}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Connection to Ordered Probit (MORP)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\"\"\n  In the Multivariate Ordered Response Probit (MORP), each dimension d\n  has ordinal categories 0, 1, ..., J_d mapped by thresholds:\n\n    Y_d = j  iff  tau_{j-1} < Y*_d <= tau_j\n\n  where tau_0 = -inf, tau_{J_d} = +inf, and Y*_d is the latent utility.\n\n  For a D-dimensional MORP, the probability of observing category\n  vector (j_1, j_2, ..., j_D) is:\n\n    P(Y = j) = P(tau_{j1-1} < Y*_1 <= tau_{j1}, ..., tau_{jD-1} < Y*_D <= tau_{jD})\n\n  After standardizing: P(Y = j) = mvncd_rect(lower, upper, sigma)\n\n  where lower_d = (tau_{jd-1} - mu_d) / sigma_d\n        upper_d = (tau_{jd}   - mu_d) / sigma_d\n\n  This is why rectangular MVNCD is essential for ordered probit models.\n\"\"\")\n\n# Quick demonstration\nprint(\"  Example: 2D ordered probit with 3 categories each\")\nthresholds = [np.array([-0.5, 0.5]), np.array([-0.3, 0.8])]\nmu = np.array([0.2, -0.1])\nsigma_err = np.array([[1.0, 0.4], [0.4, 1.0]])\n\n# P(Y1=1, Y2=2) = P(tau10 < Y1* <= tau11, tau21 < Y2* <= tau22)\nj1, j2 = 1, 2  # middle category dim1, high category dim2\nlo = np.array([\n    (thresholds[0][j1-1] - mu[0]),   # tau_0 for dim1 = -0.5\n    (thresholds[1][j2-1] - mu[1]),   # tau_1 for dim2 = 0.8\n])\nhi = np.array([\n    (thresholds[0][j1] - mu[0]),     # tau_1 for dim1 = 0.5\n    np.inf,                           # tau_2 for dim2 = +inf\n])\n\np_joint = mvncd_rect(lo, hi, sigma_err, method=\"scipy\")\nprint(f\"  P(Y1={j1}, Y2={j2}) = {p_joint:.6f}\")\nprint(f\"  (lower={lo}, upper=[{hi[0]:.1f}, inf])\")\n\nprint(f\"\\n  Next: t04c_mnp_heteronly.py â€” MNP heteroscedastic-only model\")\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}